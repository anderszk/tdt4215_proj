{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing for Power BI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: ../data/PBI/MINDsmall_csv/behaviors.csv\n",
      "Saved: ../data/PBI/MINDsmall_csv/news.csv\n",
      "Saved: ../data/PBI/MINDsmall_csv/relation_embedding.csv\n",
      "Saved: ../data/PBI/MINDsmall_csv/entity_embedding.csv\n",
      "Preview files created successfully in 'MINDsmall_csv' folder.\n"
     ]
    }
   ],
   "source": [
    "# Create output directory\n",
    "import os\n",
    "import pandas as pd\n",
    "output_folder = \"../data/PBI/MINDsmall_csv\"\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "tsv_files=[\"../data/raw/MINDsmall_dev/behaviors.tsv\", \"../data/raw/MINDsmall_dev/news.tsv\"]\n",
    "vec_files=[\"../data/raw/MINDsmall_dev/relation_embedding.vec\", \"../data/raw/MINDsmall_dev/entity_embedding.vec\"]\n",
    "\n",
    "# Function to read a file, take first 50 rows, and save it\n",
    "def process_file(file_path, output_folder, sep=\"\\t\"):\n",
    "    # Read the file\n",
    "    df = pd.read_csv(file_path, sep=sep, header=None)\n",
    "    \n",
    "    # Save to new file in preview_50 folder\n",
    "    output_filename = f\"{os.path.basename(file_path).split('.')[0]}.csv\"\n",
    "    output_path = os.path.join(output_folder, output_filename)\n",
    "    df.to_csv(output_path, index=False, header=False)\n",
    "    \n",
    "    print(f\"Saved: {output_path}\")\n",
    "\n",
    "# Process the .tsv files\n",
    "for file in tsv_files:\n",
    "    process_file(file, output_folder, sep=\"\\t\")\n",
    "\n",
    "# Process the .vec files (also tab-separated)\n",
    "for file in vec_files:\n",
    "    process_file(file, output_folder, sep=\"\\t\")\n",
    "\n",
    "print(\"Preview files created successfully in 'MINDsmall_csv' folder.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Confidence Score'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/tdt4215_proj/venv/lib/python3.13/site-packages/pandas/core/indexes/base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Confidence Score'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[27], line 41\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;66;03m# Ensure Confidence Score is properly extracted in Dim_Entities\u001b[39;00m\n\u001b[1;32m     40\u001b[0m dim_entities \u001b[38;5;241m=\u001b[39m entity_embedding_df\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[0;32m---> 41\u001b[0m dim_entities[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConfidence Score\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mdim_entities\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mConfidence Score\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[38;5;28mfloat\u001b[39m(x) \u001b[38;5;28;01mif\u001b[39;00m pd\u001b[38;5;241m.\u001b[39mnotna(x) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m     43\u001b[0m \u001b[38;5;66;03m# Compute Aggregated Click Behavior and Engagement Score for Dim_Users\u001b[39;00m\n\u001b[1;32m     44\u001b[0m user_click_counts \u001b[38;5;241m=\u001b[39m behaviors_df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUser ID\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mvalue_counts()\u001b[38;5;241m.\u001b[39mreset_index()\n",
      "File \u001b[0;32m~/tdt4215_proj/venv/lib/python3.13/site-packages/pandas/core/frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   4101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 4102\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   4104\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m~/tdt4215_proj/venv/lib/python3.13/site-packages/pandas/core/indexes/base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[1;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[1;32m   3810\u001b[0m     ):\n\u001b[1;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[0;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Confidence Score'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import ast\n",
    "\n",
    "# Create data folder\n",
    "data_folder = \"star_schema_data\"\n",
    "os.makedirs(data_folder, exist_ok=True)\n",
    "\n",
    "# Load datasets with correct column names\n",
    "behaviors_columns = [\"Impression ID\", \"User ID\", \"Time\", \"History\", \"Impressions\"]\n",
    "news_columns = [\"News ID\", \"Category\", \"SubCategory\", \"Title\", \"Abstract\", \"URL\", \"Title Entities\", \"Abstract Entities\"]\n",
    "entity_embedding_columns = [\"Entity ID\"] + [f\"Embedding_{i}\" for i in range(1, 101)]\n",
    "relation_embedding_columns = [\"Relation ID\"] + [f\"Embedding_{i}\" for i in range(1, 101)]\n",
    "\n",
    "# Load datasets\n",
    "behaviors_df = pd.read_csv(\"../data/PBI/MINDsmall_csv/behaviors.csv\", names=behaviors_columns, header=None)\n",
    "news_df = pd.read_csv(\"../data/PBI/MINDsmall_csv/news.csv\", names=news_columns, header=None)\n",
    "entity_embedding_df = pd.read_csv(\"../data/PBI/MINDsmall_csv/entity_embedding.csv\", names=entity_embedding_columns, header=None)\n",
    "relation_embedding_df = pd.read_csv(\"../data/PBI/MINDsmall_csv/relation_embedding.csv\", names=relation_embedding_columns, header=None)\n",
    "\n",
    "# Convert time format\n",
    "behaviors_df[\"Time\"] = pd.to_datetime(behaviors_df[\"Time\"], format=\"%m/%d/%Y %I:%M:%S %p\", errors='coerce')\n",
    "\n",
    "# Process entity columns\n",
    "news_df[\"Title Entities\"] = news_df[\"Title Entities\"].apply(lambda x: ast.literal_eval(x) if isinstance(x, str) else [])\n",
    "news_df[\"Abstract Entities\"] = news_df[\"Abstract Entities\"].apply(lambda x: ast.literal_eval(x) if isinstance(x, str) else [])\n",
    "\n",
    "def extract_entity_info(entity_list):\n",
    "    if not entity_list:\n",
    "        return None, None, None, None\n",
    "    entity = entity_list[0]  # Take the first entity if multiple exist\n",
    "    return entity.get(\"Label\"), entity.get(\"Type\"), entity.get(\"WikidataId\"), entity.get(\"Confidence\", None)\n",
    "\n",
    "news_df[[\"Entity Label\", \"Entity Type\", \"Wikidata ID\", \"Confidence Score\"]] = news_df[\"Title Entities\"].apply(\n",
    "    lambda x: pd.Series(extract_entity_info(x))\n",
    ")\n",
    "\n",
    "# Ensure Dim_Entities contains correct entity metadata\n",
    "if \"Confidence Score\" in entity_embedding_df.columns:\n",
    "    dim_entities = entity_embedding_df[[\"Entity ID\", \"Label\", \"Type\", \"Wikidata ID\", \"Confidence Score\"]]\n",
    "else:\n",
    "    dim_entities = entity_embedding_df[[\"Entity ID\"]]  # If Confidence Score is missing, default to Entity ID only\n",
    "\n",
    "dim_entities.to_csv(os.path.join(data_folder, \"Dim_Entities.csv\"), index=False)\n",
    "\n",
    "# Compute Aggregated Click Behavior and Engagement Score for Dim_Users\n",
    "user_click_counts = behaviors_df[\"User ID\"].value_counts().reset_index()\n",
    "user_click_counts.columns = [\"User ID\", \"Aggregated Click Behavior\"]\n",
    "user_click_counts[\"Engagement Score\"] = user_click_counts[\"Aggregated Click Behavior\"] / user_click_counts[\"Aggregated Click Behavior\"].max()\n",
    "\n",
    "dim_users = behaviors_df[[\"User ID\"]].drop_duplicates().merge(user_click_counts, on=\"User ID\", how=\"left\")\n",
    "\n",
    "# Create and save tables\n",
    "fact_impressions = behaviors_df[[\"Impression ID\", \"User ID\", \"Time\", \"History\", \"Impressions\"]]\n",
    "fact_impressions.to_csv(os.path.join(data_folder, \"Fact_Impressions.csv\"), index=False)\n",
    "\n",
    "dim_users.to_csv(os.path.join(data_folder, \"Dim_Users.csv\"), index=False)\n",
    "\n",
    "dim_news = news_df[[\"News ID\", \"Category\", \"SubCategory\", \"Title\", \"Abstract\", \"Entity Label\", \"Entity Type\", \"Wikidata ID\", \"Confidence Score\"]]\n",
    "dim_news.to_csv(os.path.join(data_folder, \"Dim_News.csv\"), index=False)\n",
    "\n",
    "dim_relations = relation_embedding_df[[\"Relation ID\"] + [f\"Embedding_{i}\" for i in range(1, 101)]]\n",
    "dim_relations.to_csv(os.path.join(data_folder, \"Dim_Relations.csv\"), index=False)\n",
    "\n",
    "# Display tables\n",
    "for name, df in zip([\"Fact_Impressions\", \"Dim_Users\", \"Dim_News\", \"Dim_Entities\", \"Dim_Relations\"], \n",
    "                     [fact_impressions, dim_users, dim_news, dim_entities, dim_relations]):\n",
    "    print(f\"{name} Table:\")\n",
    "    print(df.head(), \"\\n\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
